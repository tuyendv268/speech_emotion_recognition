encoder_dim: 256
num_layers: 6
num_attention_heads: 4
feed_forward_expansion_factor: 4
conv_expansion_factor: 2
feed_forward_dropout_p: 0.1
attention_dropout_p: 0.1
conv_dropout_p: 0.1
conv_kernel_size: 15
half_step_residual: true

cnn_kernels:
  - 3
  - 3
cnn_channels:
  - 80
  - 256
cnn_dropout: 0.1

addi_attn_dropout: 0.1